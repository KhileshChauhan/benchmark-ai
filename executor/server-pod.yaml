apiVersion: v1
kind: Pod
metadata:
  name: test-server
  namespace: default
spec:
  containers:
  - command: ["mxnet-model-server"]
    args: ["--start", "--models", "squeezenet=https://s3.amazonaws.com/model-server/model_archive_1.0/squeezenet_v1.1.mar", "--log-config=/config/log4j.properties", "--foreground"]
    image: benchmarkai/mxnet-model-server:79a39b0
    imagePullPolicy: IfNotPresent
    name: inference-server
    ports:
    - containerPort: 8080
      protocol: TCP
    resources:
      limits:
        nvidia.com/gpu: "0"
      requests:
        nvidia.com/gpu: "0"
    securityContext:
      privileged: false
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /dev/shm
      name: dshm
  restartPolicy: Never
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: metrics-pusher
  serviceAccountName: metrics-pusher
  terminationGracePeriodSeconds: 30
  volumes:
  - emptyDir:
      medium: Memory
    name: dshm
