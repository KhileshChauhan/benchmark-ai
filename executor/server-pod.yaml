#  Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.
#
#  Licensed under the Apache License, Version 2.0 (the "License").
#  You may not use this file except in compliance with the License.
#  A copy of the License is located at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  or in the "license" file accompanying this file. This file is distributed
#  on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
#  express or implied. See the License for the specific language governing
#  permissions and limitations under the License.
apiVersion: v1
kind: Pod
metadata:
  name: test-server
  namespace: default
spec:
  containers:
  - command: ["mxnet-model-server"]
    args: ["--start", "--models", "squeezenet=https://s3.amazonaws.com/model-server/model_archive_1.0/squeezenet_v1.1.mar", "--log-config=/config/log4j.properties", "--foreground"]
    image: benchmarkai/mxnet-model-server:79a39b0
    imagePullPolicy: IfNotPresent
    name: inference-server
    ports:
    - containerPort: 8080
      protocol: TCP
    resources:
      limits:
        nvidia.com/gpu: "0"
      requests:
        nvidia.com/gpu: "0"
    securityContext:
      privileged: false
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /dev/shm
      name: dshm
  restartPolicy: Never
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: metrics-pusher
  serviceAccountName: metrics-pusher
  terminationGracePeriodSeconds: 30
  volumes:
  - emptyDir:
      medium: Memory
    name: dshm
