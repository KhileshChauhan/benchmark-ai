# BenchmarkAI meta
spec_version = "0.1.0"

# These fields don't have any impact on the job to run, they contain
# merely informative data so the benchmark can be categorized when displayed
# in the dashboard.
[info]
task_name = "Title"
description = """ \
    Description of the job. Users might want to include details \
    such as whether it's inference or training, particular aspects \
    of their model, etc.\
    """

# 1. Hardware
[hardware]
instance_type = "p3.8xlarge"

# 2. Environment
[env]
# Docker hub <hub-user>/<repo-name>:<tag> 
docker_image = "mxnet/python"

# 3. Machine learning related settings: 
# dataset, benchmark code and parameters it takes
[ml]
benchmark_code = "/work/benchmarks/resnet50_inference.py"

# Dataset
[ml.data]
  # Dataset ID
  dataset = "CIFAR10"
  # Path of data download script
  download_script = "/work/download_data.sh"
  # Path where the dataset is stored in the container FS
  data_path = "/work/data/cifar10/"

# Parameters to pass to the script in ml.benchmark_code
[ml.params]
  batch_size = 32
  num_epochs = 50
  num_gpu = 8
  # Add any params you need